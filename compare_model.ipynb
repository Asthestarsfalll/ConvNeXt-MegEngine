{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b96d0b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T08:52:36.324012Z",
     "iopub.status.busy": "2022-08-06T08:52:36.323306Z",
     "iopub.status.idle": "2022-08-06T08:52:42.003941Z",
     "shell.execute_reply": "2022-08-06T08:52:42.002471Z",
     "shell.execute_reply.started": "2022-08-06T08:52:36.323838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/\n",
      "Processing ./torch-1.12.0-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: typing-extensions in /home/megstudio/.miniconda/envs/xuan/lib/python3.7/site-packages (from torch==1.12.0) (4.2.0)\n",
      "torch is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/\n",
      "Requirement already satisfied: timm in /home/megstudio/workspace/.py/lib/python3.7/site-packages (0.6.7)\n",
      "Requirement already satisfied: torch>=1.4 in /home/megstudio/workspace/.py/lib/python3.7/site-packages (from timm) (1.12.0)\n",
      "Requirement already satisfied: torchvision in /home/megstudio/workspace/.py/lib/python3.7/site-packages (from timm) (0.13.0)\n",
      "Requirement already satisfied: typing-extensions in /home/megstudio/.miniconda/envs/xuan/lib/python3.7/site-packages (from torch>=1.4->timm) (4.2.0)\n",
      "Requirement already satisfied: numpy in /home/megstudio/.miniconda/envs/xuan/lib/python3.7/site-packages (from torchvision->timm) (1.21.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/megstudio/.miniconda/envs/xuan/lib/python3.7/site-packages (from torchvision->timm) (9.1.0)\n",
      "Requirement already satisfied: requests in /home/megstudio/.miniconda/envs/xuan/lib/python3.7/site-packages (from torchvision->timm) (2.23.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/megstudio/.miniconda/envs/xuan/lib/python3.7/site-packages (from requests->torchvision->timm) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/megstudio/.miniconda/envs/xuan/lib/python3.7/site-packages (from requests->torchvision->timm) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/megstudio/.miniconda/envs/xuan/lib/python3.7/site-packages (from requests->torchvision->timm) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/megstudio/.miniconda/envs/xuan/lib/python3.7/site-packages (from requests->torchvision->timm) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "# !pip install torch-1.12.0-cp37-cp37m-manylinux1_x86_64.whl\n",
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a3d47d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T09:11:48.808078Z",
     "iopub.status.busy": "2022-08-06T09:11:48.807506Z",
     "iopub.status.idle": "2022-08-06T09:16:57.101161Z",
     "shell.execute_reply": "2022-08-06T09:16:57.099351Z",
     "shell.execute_reply.started": "2022-08-06T09:11:48.808029Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "err: failed to load cuda func: cuCtxGetCurrent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err: Failed to load cuda API library\n",
      "err: failed to load cuda func: cuCtxGetCurrent\n",
      "err: failed to load cuda func: cuDeviceGetCount\n",
      "err: failed to load cuda func: cuGetErrorString\n",
      "\u001b[33m06 09:11:52[mgb] \u001b[0m\u001b[1;31mWRN cuda unavailable: unknown cuda error(999) ndev=-1\u001b[0m\n",
      "\u001b[32m06 09:11:52 \u001b[0mload_serialized_obj_from_url: download to or using cached /home/megstudio/.cache/megengine/serialized/855c16_a9171fa3-eb68-4a74-8d1c-047e37e201ef\n",
      "abs error: 1.562148077560721e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.5708210288067903e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.582171504921348e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.5761761895660698e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.6250123469063738e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.5736441039138072e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.592561638119605e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.6006234115906182e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.5966652444632246e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.5806290720732363e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.609296251814385e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.57454638216592e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.5739933800773542e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.5551340215580467e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.5435798195184702e-09\n",
      "numpy allclose result: True\n",
      "meg time: 20.310999870300293, torch time: 251.2478005886078\n"
     ]
    }
   ],
   "source": [
    "!python ./compare.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3a8eb83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T09:05:37.772009Z",
     "iopub.status.busy": "2022-08-06T09:05:37.771384Z",
     "iopub.status.idle": "2022-08-06T09:09:31.992831Z",
     "shell.execute_reply": "2022-08-06T09:09:31.991532Z",
     "shell.execute_reply.started": "2022-08-06T09:05:37.771948Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "err: failed to load cuda func: cuCtxGetCurrent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err: Failed to load cuda API library\n",
      "err: failed to load cuda func: cuDeviceGetCount\n",
      "err: failed to load cuda func: cuGetErrorString\n",
      "\u001b[33m06 09:05:39[mgb] \u001b[0m\u001b[1;31mWRN cuda unavailable: unknown cuda error(999) ndev=-1\u001b[0m\n",
      "Begin test with rtol = 0.001, batch size =8\n",
      "\n",
      "Begin test Block:\n",
      "\t with kwards {'dim': 1024, 'drop_path': 0.2, 'layer_scale_init_value': 1e-06}:\n",
      "\t\t with shape (8, 1024, 32, 32):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: True,  100.0000% elements is close enough\n",
      " \t\t\t\t which absolute error is  6.287713269969783e-14 and absolute std is 5.03716096611484e-11\n",
      "\t\t\t\ttime used: megengine:  1.1543s, torch:  12.2308s\n",
      "Begin test ConvNeXt:\n",
      "\t with kwards {'depths': [3, 3, 9, 3], 'dims': [96, 192, 384, 768]}:\n",
      "\t\t with shape (8, 3, 32, 32):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: False,  99.9500% elements is close enough\n",
      " \t\t\t\t which absolute error is  4.2248169052072626e-07 and absolute std is 3.2380413017563114e-07\n",
      "\t\t\t\ttime used: megengine:  0.4220s, torch:  9.7396s\n",
      "\t with kwards {'depths': [3, 3, 27, 3], 'dims': [96, 192, 384, 768]}:\n",
      "\t\t with shape (8, 3, 32, 32):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: False,  99.9375% elements is close enough\n",
      " \t\t\t\t which absolute error is  4.3028185814364406e-07 and absolute std is 3.3505776286801847e-07\n",
      "\t\t\t\ttime used: megengine:  0.4962s, torch:  16.7631s\n",
      "\t with kwards {'depths': [3, 3, 27, 3], 'dims': [128, 256, 512, 1024]}:\n",
      "\t\t with shape (8, 3, 32, 32):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: False,  99.9500% elements is close enough\n",
      " \t\t\t\t which absolute error is  5.45870761925471e-07 and absolute std is 4.1297073494206415e-07\n",
      "\t\t\t\ttime used: megengine:  1.1556s, torch:  19.4113s\n",
      "\t with kwards {'depths': [3, 3, 27, 3], 'dims': [192, 384, 768, 1536]}:\n",
      "\t\t with shape (8, 3, 32, 32):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: False,  99.9500% elements is close enough\n",
      " \t\t\t\t which absolute error is  7.747430572635494e-07 and absolute std is 5.839227128490165e-07\n",
      "\t\t\t\ttime used: megengine:  3.1967s, torch:  26.7417s\n",
      "Begin test LayerNorm:\n",
      "\t with kwards {'normalized_shape': 512, 'eps': 1e-06, 'data_format': 'channels_first'}:\n",
      "\t\t with shape (8, 512, 32, 32):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: False,  99.9997% elements is close enough\n",
      " \t\t\t\t which absolute error is  1.0511546122415893e-07 and absolute std is 1.3241410101727524e-07\n",
      "\t\t\t\ttime used: megengine:  0.0003s, torch:  0.9223s\n",
      "\t with kwards {'normalized_shape': 512, 'eps': 1e-06, 'data_format': 'channels_last'}:\n",
      "\t\t with shape (8, 32, 32, 512):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: False,  99.9996% elements is close enough\n",
      " \t\t\t\t which absolute error is  1.077495639378867e-07 and absolute std is 1.3343054661163478e-07\n",
      "\t\t\t\ttime used: megengine:  0.0001s, torch:  0.5990s\n",
      "Test down, unaligned module: ['ConvNeXt', 'LayerNorm']\n"
     ]
    }
   ],
   "source": [
    "!python ./compare_modules.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d038c1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T08:53:47.986953Z",
     "iopub.status.busy": "2022-08-06T08:53:47.985675Z",
     "iopub.status.idle": "2022-08-06T08:53:48.751401Z",
     "shell.execute_reply": "2022-08-06T08:53:48.750413Z",
     "shell.execute_reply.started": "2022-08-06T08:53:47.986859Z"
    }
   },
   "outputs": [],
   "source": [
    "# megengine\n",
    "import megengine as mge\n",
    "import megengine.functional as F\n",
    "import megengine.module as M\n",
    "import numpy as np \n",
    "import math\n",
    "import megengine.hub as hub\n",
    "\n",
    "def drop_path(x, drop_prob: float = 0., training: bool = False, scale_by_keep: bool = True):\n",
    "    if drop_prob == 0. or not training:\n",
    "        return x\n",
    "    keep_prob = mge.tensor(1 - drop_prob, dtype=x.dtype)\n",
    "    size = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n",
    "    random_tensor = keep_prob + mge.random.normal(mean=0, std=1, size=size)\n",
    "    random_tensor = F.floor(random_tensor)  # binarize\n",
    "    print(random_tensor)\n",
    "    output = x / keep_prob * random_tensor\n",
    "    return output\n",
    "\n",
    "class DropPath(M.Module):\n",
    "\n",
    "    def __init__(self, drop_prob: float = 0., scale_by_keep: bool = True):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.scale_by_keep = scale_by_keep\n",
    "\n",
    "    def forward(self, x):\n",
    "        return drop_path(x, self.drop_prob, self.training, self.scale_by_keep)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f'drop_prob={round(self.drop_prob,3):0.3f}'\n",
    "\n",
    "\n",
    "class LayerNorm(M.Module):\n",
    "\n",
    "    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\"):\n",
    "        super().__init__()\n",
    "        self.weight = mge.Parameter(F.ones((normalized_shape)))\n",
    "        self.bias = mge.Parameter(F.zeros((normalized_shape)))\n",
    "        self.eps = eps\n",
    "        self.data_format = data_format\n",
    "        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n",
    "            raise NotImplementedError \n",
    "        self.normalized_shape = (normalized_shape, )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.data_format == \"channels_last\":\n",
    "            return F.nn.layer_norm(x, self.normalized_shape, True, self.weight, self.bias, self.eps)\n",
    "        elif self.data_format == \"channels_first\":\n",
    "            u = x.mean(1, keepdims=True)\n",
    "            s = F.pow((x - u), 2).mean(1, keepdims=True)\n",
    "            x = (x - u) / F.sqrt(s + self.eps)\n",
    "            x = self.weight[:, None, None] * x + self.bias[:, None, None]\n",
    "            return x\n",
    "\n",
    "\n",
    "class Block(M.Module):\n",
    "\n",
    "    def __init__(self, dim, drop_path=0., layer_scale_init_value=1e-6):\n",
    "        super().__init__()\n",
    "        self.dwconv = M.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim) # depthwise conv\n",
    "        self.norm = LayerNorm(dim, eps=1e-6)\n",
    "        self.pwconv1 = M.Linear(dim, 4 * dim) # pointwise/1x1 convs, implemented with linear layers\n",
    "        self.act = M.GELU()\n",
    "        self.pwconv2 = M.Linear(4 * dim, dim)\n",
    "        self.gamma = mge.Parameter(\n",
    "            layer_scale_init_value * F.ones((dim))) if layer_scale_init_value > 0 else None\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else M.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        inp = x\n",
    "        x = self.dwconv(x)\n",
    "        x = x.transpose(0, 2, 3, 1) # (N, C, H, W) -> (N, H, W, C)\n",
    "        x = self.norm(x)\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pwconv2(x)\n",
    "        if self.gamma is not None:\n",
    "            x = self.gamma * x\n",
    "        x = x.transpose(0, 3, 1, 2) # (N, H, W, C) -> (N, C, H, W)\n",
    "\n",
    "        x = inp + self.drop_path(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvNeXt(M.Module):\n",
    "\n",
    "    def __init__(self, in_chans=3, num_classes=1000, \n",
    "                 depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], drop_path_rate=0., \n",
    "                 layer_scale_init_value=1e-6, head_init_scale=1.,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.downsample_layers = []# stem and 3 intermediate downsampling conv layers\n",
    "        stem = M.Sequential(\n",
    "            M.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),\n",
    "            LayerNorm(dims[0], eps=1e-6, data_format=\"channels_first\")\n",
    "        )\n",
    "        self.downsample_layers.append(stem)\n",
    "        for i in range(3):\n",
    "            downsample_layer = M.Sequential(\n",
    "                    LayerNorm(dims[i], eps=1e-6, data_format=\"channels_first\"),\n",
    "                    M.Conv2d(dims[i], dims[i+1], kernel_size=2, stride=2),\n",
    "            )\n",
    "            self.downsample_layers.append(downsample_layer)\n",
    "\n",
    "        self.stages = []# 4 feature resolution stages, each consisting of multiple residual blocks\n",
    "        dp_rates=[x.item() for x in F.linspace(0, drop_path_rate, sum(depths))] \n",
    "        cur = 0\n",
    "        for i in range(4):\n",
    "            stage = M.Sequential(\n",
    "                *[Block(dim=dims[i], drop_path=dp_rates[cur + j], \n",
    "                layer_scale_init_value=layer_scale_init_value) for j in range(depths[i])]\n",
    "            )\n",
    "            self.stages.append(stage)\n",
    "            cur += depths[i]\n",
    "\n",
    "        self.norm = M.LayerNorm(dims[-1], eps=1e-6) # final norm layer\n",
    "        self.head = M.Linear(dims[-1], num_classes)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "        self.head.weight *= head_init_scale\n",
    "        self.head.bias *= (head_init_scale)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, (M.Conv2d, M.Linear)):\n",
    "            M.init.xavier_normal_(m.weight)\n",
    "            M.init.zeros_(m.bias)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        for i in range(4):\n",
    "            x = self.downsample_layers[i](x)\n",
    "            x = self.stages[i](x)\n",
    "        return self.norm(x.mean([-2, -1])) # global average pooling, (N, C, H, W) -> (N, C)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "@hub.pretrained(\n",
    "    \"https://studio.brainpp.com/api/v1/activities/3/missions/39/files/a9171fa3-eb68-4a74-8d1c-047e37e201ef\"\n",
    ")\n",
    "def convnext_tiny(pretrained=False, in_22k=False, **kwargs):\n",
    "    model = ConvNeXt(depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], **kwargs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37c576d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T08:53:50.008976Z",
     "iopub.status.busy": "2022-08-06T08:53:50.008366Z",
     "iopub.status.idle": "2022-08-06T08:54:37.786416Z",
     "shell.execute_reply": "2022-08-06T08:54:37.785061Z",
     "shell.execute_reply.started": "2022-08-06T08:53:50.008920Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "\n",
    "# All rights reserved.\n",
    "\n",
    "# This source code is licensed under the license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as tF\n",
    "from timm.models.layers import trunc_normal_, DropPath as torch_DropPath\n",
    "from timm.models.registry import register_model\n",
    "\n",
    "class torch_Block(nn.Module):\n",
    "    r\"\"\" ConvNeXt Block. There are two equivalent implementations:\n",
    "    (1) DwConv -> LayerNorm (channels_first) -> 1x1 Conv -> GELU -> 1x1 Conv; all in (N, C, H, W)\n",
    "    (2) DwConv -> Permute to (N, H, W, C); LayerNorm (channels_last) -> Linear -> GELU -> Linear; Permute back\n",
    "    We use (2) as we find it slightly faster in PyTorch\n",
    "    \n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        drop_path (float): Stochastic depth rate. Default: 0.0\n",
    "        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, drop_path=0., layer_scale_init_value=1e-6):\n",
    "        super().__init__()\n",
    "        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim) # depthwise conv\n",
    "        self.norm = torch_LayerNorm(dim, eps=1e-6)\n",
    "        self.pwconv1 = nn.Linear(dim, 4 * dim) # pointwise/1x1 convs, implemented with linear layers\n",
    "        self.act = nn.GELU()\n",
    "        self.pwconv2 = nn.Linear(4 * dim, dim)\n",
    "        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)), \n",
    "                                    requires_grad=True) if layer_scale_init_value > 0 else None\n",
    "        self.drop_path = torch_DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x\n",
    "        x = self.dwconv(x)\n",
    "        x = x.permute(0, 2, 3, 1) # (N, C, H, W) -> (N, H, W, C)\n",
    "        x = self.norm(x)\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pwconv2(x)\n",
    "        if self.gamma is not None:\n",
    "            x = self.gamma * x\n",
    "        x = x.permute(0, 3, 1, 2) # (N, H, W, C) -> (N, C, H, W)\n",
    "\n",
    "        x = input + self.drop_path(x)\n",
    "        return x\n",
    "\n",
    "class torch_ConvNeXt(nn.Module):\n",
    "    r\"\"\" ConvNeXt\n",
    "        A PyTorch impl of : `A ConvNet for the 2020s`  -\n",
    "          https://arxiv.org/pdf/2201.03545.pdf\n",
    "\n",
    "    Args:\n",
    "        in_chans (int): Number of input image channels. Default: 3\n",
    "        num_classes (int): Number of classes for classification head. Default: 1000\n",
    "        depths (tuple(int)): Number of blocks at each stage. Default: [3, 3, 9, 3]\n",
    "        dims (int): Feature dimension at each stage. Default: [96, 192, 384, 768]\n",
    "        drop_path_rate (float): Stochastic depth rate. Default: 0.\n",
    "        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.\n",
    "        head_init_scale (float): Init scaling value for classifier weights and biases. Default: 1.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_chans=3, num_classes=1000, \n",
    "                 depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], drop_path_rate=0., \n",
    "                 layer_scale_init_value=1e-6, head_init_scale=1.,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.downsample_layers = nn.ModuleList() # stem and 3 intermediate downsampling conv layers\n",
    "        stem = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),\n",
    "            torch_LayerNorm(dims[0], eps=1e-6, data_format=\"channels_first\")\n",
    "        )\n",
    "        self.downsample_layers.append(stem)\n",
    "        for i in range(3):\n",
    "            downsample_layer = nn.Sequential(\n",
    "                    torch_LayerNorm(dims[i], eps=1e-6, data_format=\"channels_first\"),\n",
    "                    nn.Conv2d(dims[i], dims[i+1], kernel_size=2, stride=2),\n",
    "            )\n",
    "            self.downsample_layers.append(downsample_layer)\n",
    "\n",
    "        self.stages = nn.ModuleList() # 4 feature resolution stages, each consisting of multiple residual blocks\n",
    "        dp_rates=[x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))] \n",
    "        cur = 0\n",
    "        for i in range(4):\n",
    "            stage = nn.Sequential(\n",
    "                *[torch_Block(dim=dims[i], drop_path=dp_rates[cur + j], \n",
    "                layer_scale_init_value=layer_scale_init_value) for j in range(depths[i])]\n",
    "            )\n",
    "            self.stages.append(stage)\n",
    "            cur += depths[i]\n",
    "\n",
    "        self.norm = nn.LayerNorm(dims[-1], eps=1e-6) # final norm layer\n",
    "        self.head = nn.Linear(dims[-1], num_classes)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "        self.head.weight.data.mul_(head_init_scale)\n",
    "        self.head.bias.data.mul_(head_init_scale)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        for i in range(4):\n",
    "            x = self.downsample_layers[i](x)\n",
    "            x = self.stages[i](x)\n",
    "        return self.norm(x.mean([-2, -1])) # global average pooling, (N, C, H, W) -> (N, C)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "class torch_LayerNorm(nn.Module):\n",
    "    r\"\"\" LayerNorm that supports two data formats: channels_last (default) or channels_first. \n",
    "    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with \n",
    "    shape (batch_size, height, width, channels) while channels_first corresponds to inputs \n",
    "    with shape (batch_size, channels, height, width).\n",
    "    \"\"\"\n",
    "    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\"):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
    "        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
    "        self.eps = eps\n",
    "        self.data_format = data_format\n",
    "        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n",
    "            raise NotImplementedError \n",
    "        self.normalized_shape = (normalized_shape, )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.data_format == \"channels_last\":\n",
    "            return tF.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
    "        elif self.data_format == \"channels_first\":\n",
    "            u = x.mean(1, keepdim=True)\n",
    "            s = (x - u).pow(2).mean(1, keepdim=True)\n",
    "            x = (x - u) / torch.sqrt(s + self.eps)\n",
    "            x = self.weight[:, None, None] * x + self.bias[:, None, None]\n",
    "            return x\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    \"convnext_tiny_1k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth\",\n",
    "    \"convnext_small_1k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_small_1k_224_ema.pth\",\n",
    "    \"convnext_base_1k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_base_1k_224_ema.pth\",\n",
    "    \"convnext_large_1k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_large_1k_224_ema.pth\",\n",
    "    \"convnext_tiny_22k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_tiny_22k_224.pth\",\n",
    "    \"convnext_small_22k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_small_22k_224.pth\",\n",
    "    \"convnext_base_22k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_224.pth\",\n",
    "    \"convnext_large_22k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_224.pth\",\n",
    "    \"convnext_xlarge_22k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_xlarge_22k_224.pth\",\n",
    "}\n",
    "\n",
    "@register_model\n",
    "def torch_convnext_tiny(pretrained=False,in_22k=False, **kwargs):\n",
    "    model = torch_ConvNeXt(depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], **kwargs)\n",
    "    if pretrained:\n",
    "        url = model_urls['convnext_tiny_22k'] if in_22k else model_urls['convnext_tiny_1k']\n",
    "        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location=\"cpu\", check_hash=True)\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "    return model\n",
    "\n",
    "# @register_model\n",
    "# def convnext_small(pretrained=False,in_22k=False, **kwargs):\n",
    "#     model = ConvNeXt(depths=[3, 3, 27, 3], dims=[96, 192, 384, 768], **kwargs)\n",
    "#     if pretrained:\n",
    "#         url = model_urls['convnext_small_22k'] if in_22k else model_urls['convnext_small_1k']\n",
    "#         checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location=\"cpu\")\n",
    "#         model.load_state_dict(checkpoint[\"model\"])\n",
    "#     return model\n",
    "\n",
    "# @register_model\n",
    "# def convnext_base(pretrained=False, in_22k=False, **kwargs):\n",
    "#     model = ConvNeXt(depths=[3, 3, 27, 3], dims=[128, 256, 512, 1024], **kwargs)\n",
    "#     if pretrained:\n",
    "#         url = model_urls['convnext_base_22k'] if in_22k else model_urls['convnext_base_1k']\n",
    "#         checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location=\"cpu\")\n",
    "#         model.load_state_dict(checkpoint[\"model\"])\n",
    "#     return model\n",
    "\n",
    "# @register_model\n",
    "# def convnext_large(pretrained=False, in_22k=False, **kwargs):\n",
    "#     model = ConvNeXt(depths=[3, 3, 27, 3], dims=[192, 384, 768, 1536], **kwargs)\n",
    "#     if pretrained:\n",
    "#         url = model_urls['convnext_large_22k'] if in_22k else model_urls['convnext_large_1k']\n",
    "#         checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location=\"cpu\")\n",
    "#         model.load_state_dict(checkpoint[\"model\"])\n",
    "#     return model\n",
    "\n",
    "# @register_model\n",
    "# def convnext_xlarge(pretrained=False, in_22k=False, **kwargs):\n",
    "#     model = ConvNeXt(depths=[3, 3, 27, 3], dims=[256, 512, 1024, 2048], **kwargs)\n",
    "#     if pretrained:\n",
    "#         assert in_22k, \"only ImageNet-22K pre-trained ConvNeXt-XL is available; please set in_22k=True\"\n",
    "#         url = model_urls['convnext_xlarge_22k']\n",
    "#         checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location=\"cpu\")\n",
    "#         model.load_state_dict(checkpoint[\"model\"])\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f72b639",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T08:56:03.601412Z",
     "iopub.status.busy": "2022-08-06T08:56:03.600994Z",
     "iopub.status.idle": "2022-08-06T09:01:28.592665Z",
     "shell.execute_reply": "2022-08-06T09:01:28.590934Z",
     "shell.execute_reply.started": "2022-08-06T08:56:03.601388Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m06 08:56:03 \u001b[0mload_serialized_obj_from_url: download to or using cached /home/megstudio/.cache/megengine/serialized/855c16_a9171fa3-eb68-4a74-8d1c-047e37e201ef\n",
      "100%|███████████████████████████████████████| 114M/114M [00:11<00:00, 10.3MiB/s]\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth\" to /home/megstudio/.cache/torch/hub/checkpoints/convnext_tiny_1k_224_ema.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d17bf43194044559d01f0fc93caca80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/109M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abs error: 1.5822005927645932e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.5312688894653093e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.5734694658320336e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.6321719531475765e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.6188133056260767e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.6298145055770874e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.5592668267672138e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.5797267938211235e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.6069389152661984e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.634762103464027e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.5752157356274665e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.638633007061685e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.5602563685490622e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.6049598317025016e-09\n",
      "numpy allclose result: True\n",
      "abs error: 1.5903788286308895e-09\n",
      "numpy allclose result: True\n",
      "meg time: 20.72342300415039, torch time: 243.97850036621094\n"
     ]
    }
   ],
   "source": [
    "import megengine as mge\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "\n",
    "mge_model = convnext_tiny(True)\n",
    "# mge_model.load_state_dict(mge.load('./convnext_tiny_1k_224_ema.pkl'))\n",
    "torch_model = torch_convnext_tiny(pretrained=True)\n",
    "torch_time = meg_time = 0.0\n",
    "\n",
    "def softmax(logits):\n",
    "    logits = logits - logits.max(-1, keepdims=True)\n",
    "    exp = np.exp(logits)\n",
    "    return exp / exp.sum(-1, keepdims=True)\n",
    "\n",
    "for i in range(15):\n",
    "    inp = np.random.randn(2, 3, 224, 224)\n",
    "    mge_inp = mge.tensor(inp, dtype=np.float32)\n",
    "    torch_inp = torch.tensor(inp, dtype=torch.float32)\n",
    "    if torch.cuda.is_available():\n",
    "        torch_inp = torch_inp.cuda()\n",
    "\n",
    "    st = time.time()\n",
    "    mge_out = mge_model(mge_inp)\n",
    "    meg_time += time.time() - st\n",
    "\n",
    "    st = time.time()\n",
    "    torch_out = torch_model(torch_inp)\n",
    "    torch_time += time.time() - st\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch_out = torch_out.detach().cpu().numpy()\n",
    "    else:\n",
    "        torch_out = torch_out.detach().numpy()\n",
    "    mge_out = mge_out.numpy()\n",
    "    mge_out = softmax(mge_out)\n",
    "    torch_out = softmax(torch_out)\n",
    "    print(f\"abs error: {np.mean(np.abs(torch_out - mge_out))}\")\n",
    "    print(f\"numpy allclose result: {np.allclose(torch_out, mge_out, rtol=1e-3)}\")\n",
    "\n",
    "print(f\"meg time: {meg_time}, torch time: {torch_time}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85d74ddf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T09:19:40.117724Z",
     "iopub.status.busy": "2022-08-06T09:19:40.117034Z",
     "iopub.status.idle": "2022-08-06T09:20:20.596974Z",
     "shell.execute_reply": "2022-08-06T09:20:20.596215Z",
     "shell.execute_reply.started": "2022-08-06T09:19:40.117654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin test with rtol = 0.001, batch size =8\n",
      "\n",
      "Begin test GELU:\n",
      "\t with kwards {}:\n",
      "\t\t with shape (8, 150, 32, 32):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: False,  99.9993% elements is close enough\n",
      " \t\t\t\t which absolute error is  3.833242701034578e-08 and absolute std is 4.615024806753354e-08\n",
      "\t\t\t\ttime used: megengine:  0.0002s, torch:  0.1821s\n",
      "Begin test RELU:\n",
      "\t with kwards {}:\n",
      "\t\t with shape (8, 468, 32, 32):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: True,  100.0000% elements is close enough\n",
      " \t\t\t\t which absolute error is  0.0 and absolute std is 0.0\n",
      "\t\t\t\ttime used: megengine:  0.0001s, torch:  0.1475s\n",
      "Begin test LeakyReLU:\n",
      "\t with kwards {}:\n",
      "\t\t with shape (8, 1648, 32, 32):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: True,  100.0000% elements is close enough\n",
      " \t\t\t\t which absolute error is  0.0 and absolute std is 0.0\n",
      "\t\t\t\ttime used: megengine:  0.0006s, torch:  0.2993s\n",
      "Begin test SIGMOID:\n",
      "\t with kwards {}:\n",
      "\t\t with shape (8, 1051, 32, 32):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: True,  100.0000% elements is close enough\n",
      " \t\t\t\t which absolute error is  2.4980978396982323e-10 and absolute std is 3.590702402078705e-09\n",
      "\t\t\t\ttime used: megengine:  0.0001s, torch:  0.4958s\n",
      "Begin test MaxPool2d:\n",
      "\t with kwards {'kernel_size': 3, 'stride': 2, 'padding': 1}:\n",
      "\t\t with shape (8, 782, 32, 32):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: True,  100.0000% elements is close enough\n",
      " \t\t\t\t which absolute error is  0.0 and absolute std is 0.0\n",
      "\t\t\t\ttime used: megengine:  0.0002s, torch:  0.7286s\n",
      "\t with kwards {'kernel_size': 3, 'stride': 1, 'padding': 1}:\n",
      "\t\t with shape (8, 1126, 32, 32):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: True,  100.0000% elements is close enough\n",
      " \t\t\t\t which absolute error is  0.0 and absolute std is 0.0\n",
      "\t\t\t\ttime used: megengine:  0.0002s, torch:  1.0996s\n",
      "\t with kwards {'kernel_size': 2, 'stride': 2, 'padding': 0}:\n",
      "\t\t with shape (8, 1290, 32, 32):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: True,  100.0000% elements is close enough\n",
      " \t\t\t\t which absolute error is  0.0 and absolute std is 0.0\n",
      "\t\t\t\ttime used: megengine:  0.0002s, torch:  0.4017s\n",
      "Begin test AvgPool2d:\n",
      "\t with kwards {'kernel_size': 3, 'stride': 2, 'padding': 1}:\n",
      "\t\t with shape (8, 1368, 32, 32):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: True,  100.0000% elements is close enough\n",
      " \t\t\t\t which absolute error is  0.0 and absolute std is 0.0\n",
      "\t\t\t\ttime used: megengine:  0.0002s, torch:  0.5961s\n",
      "\t with kwards {'kernel_size': 3, 'stride': 1, 'padding': 1}:\n",
      "\t\t with shape (8, 93, 32, 32):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: True,  100.0000% elements is close enough\n",
      " \t\t\t\t which absolute error is  0.0 and absolute std is 0.0\n",
      "\t\t\t\ttime used: megengine:  0.0002s, torch:  0.1115s\n",
      "\t with kwards {'kernel_size': 2, 'stride': 2, 'padding': 0}:\n",
      "\t\t with shape (8, 1991, 32, 32):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: True,  100.0000% elements is close enough\n",
      " \t\t\t\t which absolute error is  0.0 and absolute std is 0.0\n",
      "\t\t\t\ttime used: megengine:  0.0003s, torch:  0.3026s\n",
      "Begin test Standrd Conv2d:\n",
      "\t with kwards {'in_channels': 512, 'out_channels': 1024, 'kernel_size': 3, 'stride': 1, 'padding': 1}:\n",
      "\t\t with shape (8, 512, 32, 32):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: False,  99.9770% elements is close enough\n",
      " \t\t\t\t which absolute error is  1.8167615678521543e-07 and absolute std is 1.453699383091589e-07\n",
      "\t\t\t\ttime used: megengine:  0.0004s, torch:  2.3012s\n",
      "\t with kwards {'in_channels': 256, 'out_channels': 512, 'kernel_size': 7, 'stride': 3, 'padding': 1}:\n",
      "\t\t with shape (8, 256, 32, 32):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: False,  99.9624% elements is close enough\n",
      " \t\t\t\t which absolute error is  2.600152981813153e-07 and absolute std is 2.0325813920862856e-07\n",
      "\t\t\t\ttime used: megengine:  0.0001s, torch:  1.1419s\n",
      "\t with kwards {'in_channels': 1024, 'out_channels': 1000, 'kernel_size': 1, 'stride': 1, 'padding': 0}:\n",
      "\t\t with shape (8, 1024, 32, 32):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: False,  99.9812% elements is close enough\n",
      " \t\t\t\t which absolute error is  1.6188734264233062e-07 and absolute std is 1.3855949987373606e-07\n",
      "\t\t\t\ttime used: megengine:  0.0002s, torch:  0.9002s\n",
      "Begin test Group Conv2d:\n",
      "\t with kwards {'in_channels': 512, 'out_channels': 512, 'kernel_size': 3, 'stride': 1, 'padding': 1, 'groups': 512}:\n",
      "\t\t with shape (8, 512, 32, 32):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: False,  99.9988% elements is close enough\n",
      " \t\t\t\t which absolute error is  2.8214685698912945e-08 and absolute std is 3.48608040212639e-08\n",
      "\t\t\t\ttime used: megengine:  0.0002s, torch:  0.3993s\n",
      "\t with kwards {'in_channels': 256, 'out_channels': 256, 'kernel_size': 7, 'stride': 3, 'padding': 1, 'groups': 128}:\n",
      "\t\t with shape (8, 256, 32, 32):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: True,  100.0000% elements is close enough\n",
      " \t\t\t\t which absolute error is  0.0 and absolute std is 0.0\n",
      "\t\t\t\ttime used: megengine:  0.0001s, torch:  0.1101s\n",
      "Begin test GroupNorm:\n",
      "\t with kwards {'num_groups': 256, 'num_channels': 512, 'eps': 1e-06, 'affine': True}:\n",
      "\t\t with shape (8, 512, 32, 32):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: False,  99.9999% elements is close enough\n",
      " \t\t\t\t which absolute error is  6.175130096153225e-08 and absolute std is 8.416149199774736e-08\n",
      "\t\t\t\ttime used: megengine:  0.0004s, torch:  0.2996s\n",
      "\t with kwards {'num_groups': 256, 'num_channels': 512, 'eps': 1e-06, 'affine': False}:\n",
      "\t\t with shape (8, 512, 32, 32):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: False,  99.9999% elements is close enough\n",
      " \t\t\t\t which absolute error is  6.1897040382064e-08 and absolute std is 8.330573564307997e-08\n",
      "\t\t\t\ttime used: megengine:  0.0002s, torch:  0.2588s\n",
      "Begin test BatchNorm:\n",
      "\t with kwards {'num_features': 512, 'eps': 1e-06}:\n",
      "\t\t with shape (8, 512, 32, 32):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: True,  100.0000% elements is close enough\n",
      " \t\t\t\t which absolute error is  1.6209256159527285e-13 and absolute std is 1.1783114761687585e-10\n",
      "\t\t\t\ttime used: megengine:  0.0001s, torch:  0.1539s\n",
      "\t with kwards {'num_features': 512, 'eps': 1e-05}:\n",
      "\t\t with shape (8, 512, 32, 32):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: True,  100.0000% elements is close enough\n",
      " \t\t\t\t which absolute error is  3.020432515210558e-11 and absolute std is 1.8035190008092172e-09\n",
      "\t\t\t\ttime used: megengine:  0.0001s, torch:  0.2965s\n",
      "Begin test LayerNorm:\n",
      "\t with kwards {'normalized_shape': 512, 'eps': 1e-06}:\n",
      "\t\t with shape (8, 32, 32, 512):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: False,  99.9994% elements is close enough\n",
      " \t\t\t\t which absolute error is  1.0580205156429656e-07 and absolute std is 1.31404277681213e-07\n",
      "\t\t\t\ttime used: megengine:  0.0001s, torch:  0.3713s\n",
      "Begin test Not affine LayerNorm:\n",
      "\t with kwards {'normalized_shape': 512, 'eps': 1e-06}:\n",
      "\t\t with shape (8, 32, 32, 512):\n",
      "\t\t\t with dtype float32:\n",
      "\t\t\t\tResult: False,  99.9995% elements is close enough\n",
      " \t\t\t\t which absolute error is  1.0826219920545554e-07 and absolute std is 1.3245123398064607e-07\n",
      "\t\t\t\ttime used: megengine:  0.0001s, torch:  0.2045s\n",
      "Test down, unaligned module: ['LayerNorm', 'GroupNorm', 'Standrd Conv2d', 'GELU', 'Not affine LayerNorm', 'Group Conv2d']\n"
     ]
    }
   ],
   "source": [
    "# test alignment between megengine and torch, \n",
    "# after testing, I found that some base api are not aligned with the standard(relative error below 1e-3)\n",
    "# such base api are not aligned:\n",
    "#   Conv2d\n",
    "#   GELU\n",
    "#   GroupNorm\n",
    "#   LayerNorm (when input is large, I only test the input with shape [8, 512] and  [8, 512, 32, 32])\n",
    "\n",
    "from functools import partial\n",
    "import time\n",
    "\n",
    "GLOBAL_RTOL = 1e-3\n",
    "BATCH_SIZE = 8\n",
    "# TEST_SP_DIM = [32, 64, 224, 512, 1024]\n",
    "TEST_SP_DIM = [32]\n",
    "\n",
    "DTYPE_MAPPER = {\n",
    "    # 'float16': (np.float16, torch.float16),\n",
    "    'float32': (np.float32, torch.float32),\n",
    "    # 'float64': (np.float64, torch.float64),\n",
    "}\n",
    "\n",
    "KWARDS_MAPPER = {\n",
    "    \"Block\": [\n",
    "        {\"dim\": 1024, \"drop_path\": 0.2, \"layer_scale_init_value\":1e-6}\n",
    "    ],\n",
    "    \"ConvNeXt\": [\n",
    "        {\"depths\": [3, 3, 9, 3], \"dims\": [96, 192, 384, 768]}, # tiny\n",
    "#         {\"depths\": [3, 3, 27, 3], \"dims\": [96, 192, 384, 768]}, # small\n",
    "#         {\"depths\": [3, 3, 27, 3], \"dims\": [128, 256, 512, 1024]}, # base\n",
    "#         {\"depths\": [3, 3, 27, 3], \"dims\": [192, 384, 768, 1536]}, # large\n",
    "    ],\n",
    "    \"LayerNorm\": [\n",
    "        {\"normalized_shape\": 512, \"eps\": 1e-6, \"data_format\": \"channels_first\"},\n",
    "        {\"normalized_shape\": 512, \"eps\": 1e-6, \"data_format\": \"channels_last\"},\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "CLASS_MAPPER = {\n",
    "    \"Block\": (Block, torch_Block),\n",
    "    \"ConvNeXt\": (ConvNeXt, torch_ConvNeXt),\n",
    "    \"LayerNorm\": (LayerNorm, torch_LayerNorm),\n",
    "}\n",
    "\n",
    "# test base api\n",
    "\n",
    "KWARDS_MAPPER = {\n",
    "    \"Standrd Conv2d\": (\n",
    "        {\"in_channels\": 512, \"out_channels\": 1024,\n",
    "            \"kernel_size\": 3, \"stride\": 1, \"padding\": 1},\n",
    "        {\"in_channels\": 256, \"out_channels\": 512,\n",
    "            \"kernel_size\": 7, \"stride\": 3, \"padding\": 1},\n",
    "        {\"in_channels\": 1024, \"out_channels\": 1000,\n",
    "            \"kernel_size\": 1, \"stride\": 1, \"padding\": 0},\n",
    "    ),\n",
    "    \"Group Conv2d\": (\n",
    "        {\"in_channels\": 512, \"out_channels\": 512,\n",
    "            \"kernel_size\": 3, \"stride\": 1, \"padding\": 1, \"groups\": 512},\n",
    "        {\"in_channels\": 256, \"out_channels\": 256,\n",
    "            \"kernel_size\": 7, \"stride\": 3, \"padding\": 1, \"groups\": 128},\n",
    "    ),\n",
    "    \"GroupNorm\": (\n",
    "        {\"num_groups\": 256, \"num_channels\": 512, \"eps\": 1e-6, \"affine\": True},\n",
    "        {\"num_groups\": 256, \"num_channels\": 512, \"eps\": 1e-6, \"affine\": False},\n",
    "    ),\n",
    "    \"LayerNorm\": (\n",
    "        {\"normalized_shape\": 512, \"eps\": 1e-6},\n",
    "    ),\n",
    "    \"Not affine LayerNorm\": (\n",
    "        {\"normalized_shape\": 512, \"eps\": 1e-6},\n",
    "    ),\n",
    "    \"BatchNorm\": ( \n",
    "        {\"num_features\": 512, \"eps\": 1e-6},\n",
    "        {\"num_features\": 512, \"eps\": 1e-5},\n",
    "    ),\n",
    "    \"MaxPool2d\": (\n",
    "        {\"kernel_size\": 3, \"stride\": 2, \"padding\": 1},\n",
    "        {\"kernel_size\": 3, \"stride\": 1, \"padding\": 1},\n",
    "        {\"kernel_size\": 2, \"stride\": 2, \"padding\": 0},\n",
    "    ),\n",
    "    \"AvgPool2d\": (\n",
    "        {\"kernel_size\": 3, \"stride\": 2, \"padding\": 1},\n",
    "        {\"kernel_size\": 3, \"stride\": 1, \"padding\": 1},\n",
    "        {\"kernel_size\": 2, \"stride\": 2, \"padding\": 0},\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "CLASS_MAPPER = {\n",
    "    \"GELU\": (M.GELU, nn.GELU),\n",
    "    \"RELU\": (M.ReLU, nn.ReLU),\n",
    "    \"LeakyReLU\": (M.LeakyReLU, nn.LeakyReLU),\n",
    "    \"SIGMOID\": (M.Sigmoid, nn.Sigmoid),\n",
    "    \"MaxPool2d\": (M.MaxPool2d, nn.MaxPool2d),\n",
    "    \"AvgPool2d\": (M.AvgPool2d, partial(nn.AvgPool2d, count_include_pad=False)),\n",
    "    \"Standrd Conv2d\": (M.Conv2d, nn.Conv2d),\n",
    "    \"Group Conv2d\": (M.Conv2d, nn.Conv2d),\n",
    "    \"GroupNorm\": (M.GroupNorm, nn.GroupNorm),\n",
    "    \"BatchNorm\": (M.BatchNorm2d, nn.BatchNorm2d),\n",
    "    \"LayerNorm\": (M.LayerNorm, nn.LayerNorm),\n",
    "    \"Not affine LayerNorm\": (partial(M.LayerNorm, affine=False), partial(nn.LayerNorm, elementwise_affine=False)),\n",
    "}\n",
    "\n",
    "\n",
    "def generate_inputs(shape, dtype='float32'):\n",
    "    inp = np.random.randn(*shape)\n",
    "    types = DTYPE_MAPPER[dtype]\n",
    "    mge_inp = mge.tensor(inp, dtype=types[0])\n",
    "    torch_inp = torch.tensor(inp, dtype=types[1])\n",
    "    return mge_inp, torch_inp\n",
    "\n",
    "\n",
    "def get_atttr_by_name(torch_module, k):\n",
    "    name_list = k.split('.')\n",
    "    sub_module = getattr(torch_module, name_list[0])\n",
    "    if len(name_list) != 1:\n",
    "        for i in name_list[1:-1]:\n",
    "            try:\n",
    "                sub_module = getattr(sub_module, i)\n",
    "            except:\n",
    "                sub_module = sub_module[int(i)]\n",
    "    return torch_module\n",
    "\n",
    "\n",
    "def convert_state_dict(torch_module, torch_dict):\n",
    "    mge_dict = {}\n",
    "    for k, v in torch_dict.items():\n",
    "        data = v.numpy()\n",
    "        sub_module = get_atttr_by_name(torch_module, k)\n",
    "        is_conv = isinstance(sub_module, nn.Conv2d)\n",
    "        if is_conv:\n",
    "            groups = sub_module.groups\n",
    "            is_group = groups > 1\n",
    "        else:\n",
    "            is_group = False\n",
    "        if \"weight\" in k and is_group:\n",
    "            out_ch, in_ch, h, w = data.shape\n",
    "            data = data.reshape(groups, out_ch // groups, in_ch, h, w)\n",
    "        if \"bias\" in k and not is_in_string(['norm', 'pwconv'], k):\n",
    "            if is_conv:\n",
    "                data = data.reshape(1, -1, 1, 1)\n",
    "        if \"num_batches_tracked\" in k:\n",
    "            continue\n",
    "        mge_dict[k] = data\n",
    "\n",
    "    return mge_dict\n",
    "\n",
    "\n",
    "def is_in_string(targets: list, s: str):\n",
    "    return any(t in s for t in targets)\n",
    "\n",
    "\n",
    "def convert_dtype(m):\n",
    "    pass\n",
    "\n",
    "\n",
    "def test_func(mge_tensor, torch_tensor):\n",
    "    mge_out = mge_tensor.numpy()\n",
    "    if torch.cuda.is_available():\n",
    "        torch_out = torch_tensor.detach().cpu().numpy()\n",
    "    else:\n",
    "        torch_out = torch_tensor.detach().numpy()\n",
    "    result = np.isclose(mge_out, torch_out, rtol=GLOBAL_RTOL)\n",
    "    ratio = np.mean(result)\n",
    "    allclose = np.all(result) > 0\n",
    "    abs_err = np.mean(np.abs(mge_out - torch_out))\n",
    "    std_err = np.std(np.abs(mge_out - torch_out))\n",
    "    return ratio, allclose, abs_err, std_err\n",
    "\n",
    "\n",
    "def get_channels(kwards):\n",
    "    for n in ['dim', 'normalized_shape', 'in_channels', 'num_channels', 'normalized_shape', 'num_features']:\n",
    "        if n in kwards:\n",
    "            ch = kwards[n]\n",
    "            if isinstance(ch, list):\n",
    "                return ch\n",
    "            return [ch]\n",
    "    else:\n",
    "        if 'dims' in kwards:\n",
    "            return [3]\n",
    "        return list(np.random.randint(1, 2048, size=[1]))\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(f\"Begin test with rtol = {GLOBAL_RTOL}, batch size ={BATCH_SIZE}\")\n",
    "    print()\n",
    "    unalign_list = []\n",
    "    for k, (mge_class, torch_class) in CLASS_MAPPER.items():\n",
    "        kwards = KWARDS_MAPPER.get(k, [{}])\n",
    "        print(f\"Begin test {k}:\")\n",
    "        for kw in kwards:\n",
    "            print(f\"\\t with kwards {kw}:\")\n",
    "            mge_module = mge_class(**kw)\n",
    "            mge_module.eval()\n",
    "            torch_module = torch_class(**kw)\n",
    "            torch_module.eval()\n",
    "            channels = get_channels(kw)\n",
    "            for sp_dim in TEST_SP_DIM:\n",
    "                input_shape = (BATCH_SIZE, *channels, sp_dim, sp_dim)\n",
    "                for dtype in DTYPE_MAPPER.keys():\n",
    "                    mge_inp, torch_inp = generate_inputs(input_shape, dtype)\n",
    "#                     if \"LayerNorm\" in k and kw[\"data_format\"] == \"channels_last\":                    \n",
    "                    if \"LayerNorm\" in k:\n",
    "                        mge_inp = mge_inp.transpose(0, 2, 3, 1)\n",
    "                        torch_inp = torch_inp.permute(0, 2, 3, 1)\n",
    "                    print(f\"\\t\\t with shape {mge_inp.shape}:\")\n",
    "                    print(f\"\\t\\t\\t with dtype {dtype}:\")\n",
    "                    torch_dict = torch_module.state_dict()\n",
    "                    mge_dict = convert_state_dict(torch_module, torch_dict)\n",
    "                    mge_module.load_state_dict(mge_dict)\n",
    "\n",
    "                    st = time.time()\n",
    "                    mge_out = mge_module(mge_inp)\n",
    "                    mge_time = time.time() - st\n",
    "\n",
    "                    st = time.time()\n",
    "                    torch_out = torch_module(torch_inp)\n",
    "                    torch_time = time.time() - st\n",
    "\n",
    "                    ratio, allclose, abs_err, std_err = test_func(mge_out, torch_out)\n",
    "                    if not allclose:\n",
    "                        unalign_list.append(k)\n",
    "                    print(f\"\\t\\t\\t\\tResult: {allclose}, {ratio*100 : .4f}% elements is close enough\\n \\t\\t\\t\\t which absolute error is  {abs_err} and absolute std is {std_err}\")\n",
    "                    print(f\"\\t\\t\\t\\ttime used: megengine: {mge_time : .4f}s, torch: {torch_time : .4f}s\")\n",
    "    print(f\"Test down, unaligned module: {list(set(unalign_list))}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    a = M.Conv2d(1, 1, 1)\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b99f668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
